{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knull/miniconda3/envs/auto-seg/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%run imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_model_complexity(model, input_res):\n",
    "#     macs, params = get_model_complexity_info(model, input_res, as_strings=False, print_per_layer_stat=False)\n",
    "#     gflops = macs / 1e9 \n",
    "#     params_million = params / 1e6 \n",
    "#     return params_million, gflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size = (3, 256, 256)\n",
    "# segformer_variants = [\"b0\", \"b1\", \"b2\", \"b3\", \"b4\", \"b5\"]\n",
    "# unet_variants = [32, 64, 86, 114, 128, 156]\n",
    "\n",
    "# for i in range(len(segformer_variants)):\n",
    "#     segformer = select_model(model_name=\"segformer\", model_config=segformer_variants[i])\n",
    "#     seg_params, seg_gflops = calculate_model_complexity(segformer, input_size)\n",
    "\n",
    "#     unet = select_model(model_name=\"unet\", model_config=unet_variants[i])\n",
    "#     unet_params, unet_gflops = calculate_model_complexity(unet, input_size)\n",
    "        \n",
    "#     print(f\"Segformer ({segformer_variants[i]})\\t Params(M): {seg_params:.2f}\\tGFLOPs: {seg_gflops:.2f} | UNet ({unet_variants[i]})\\t Params(M): {unet_params:.2f}\\tGFLOPs: {unet_gflops:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = str(env_vars[\"results_root\"])\n",
    "ablation_kfold_path = f\"{ROOT}/ablation-studies\"\n",
    "\n",
    "model_name = \"segformer\"\n",
    "model_configs = [\"b0\", \"b1\", \"b2\", \"b3\"]\n",
    "variants = [\"size_256x64\", \"size_320x80\", \"size_384x96\"]\n",
    "results_fname = \"results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segformer-b0, Used Image size: 256x64 => Dice: 0.820084, mIoU: 0.698333\n",
      "segformer-b1, Used Image size: 256x64 => Dice: 0.824564, mIoU: 0.703814\n",
      "segformer-b2, Used Image size: 256x64 => Dice: 0.837433, mIoU: 0.723890\n",
      "segformer-b2, Used Image size: 320x80 => Dice: 0.840771, mIoU: 0.728543\n",
      "segformer-b2, Used Image size: 384x96 => Dice: 0.853057, mIoU: 0.747256\n",
      "segformer-b3, Used Image size: 256x64 => Dice: 0.835593, mIoU: 0.721535\n",
      "segformer-b3, Used Image size: 320x80 => Dice: 0.844847, mIoU: 0.734612\n",
      "segformer-b3, Used Image size: 384x96 => Dice: 0.841592, mIoU: 0.730296\n"
     ]
    }
   ],
   "source": [
    "for model_config in model_configs:\n",
    "    if model_config==\"b0\" or model_config==\"b1\":\n",
    "        variant = str(variants[0])\n",
    "        kfold_results_path = f'{ablation_kfold_path}/{model_name}_{model_config}.{variant}.{results_fname}'\n",
    "        with open(f'{kfold_results_path}', 'r') as file:\n",
    "            kfold_data = json.load(file)\n",
    "\n",
    "        keys = list(kfold_data.keys())\n",
    "        \n",
    "        benchmark_dice_score, benchmark_miou_score = 0.0, 0.0\n",
    "        for key in keys:\n",
    "            benchmark_dice_score += kfold_data[key][\"test_dice_score\"]\n",
    "            benchmark_miou_score += kfold_data[key][\"test_miou_score\"]\n",
    "            \n",
    "        benchmark_dice_score, benchmark_miou_score = benchmark_dice_score/len(keys), benchmark_miou_score/len(keys)\n",
    "        benchmark_dice_score, benchmark_miou_score\n",
    "        print(f\"{model_name}-{model_config}, Used Image size: {variant.split('_')[1]} => Dice: {benchmark_dice_score:2f}, mIoU: {benchmark_miou_score:2f}\")\n",
    "    \n",
    "    else:\n",
    "        for variant in variants:\n",
    "            kfold_results_path = f'{ablation_kfold_path}/{model_name}_{model_config}.{variant}.{results_fname}'\n",
    "            with open(f'{kfold_results_path}', 'r') as file:\n",
    "                kfold_data = json.load(file)\n",
    "\n",
    "            keys = list(kfold_data.keys())\n",
    "            benchmark_dice_score, benchmark_miou_score = 0.0, 0.0\n",
    "            for key in keys:\n",
    "                benchmark_dice_score += kfold_data[key][\"test_dice_score\"]\n",
    "                benchmark_miou_score += kfold_data[key][\"test_miou_score\"]\n",
    "                \n",
    "            benchmark_dice_score, benchmark_miou_score = benchmark_dice_score/len(keys), benchmark_miou_score/len(keys)\n",
    "            benchmark_dice_score, benchmark_miou_score\n",
    "            print(f\"{model_name}-{model_config}, Used Image size: {variant.split('_')[1]} => Dice: {benchmark_dice_score:2f}, mIoU: {benchmark_miou_score:2f}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results - Segformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGFORMER_FINAL_RESULTS_ROOT = f\"{ROOT}/final-results-with-segformer\"\n",
    "seg_kfold_path = f\"{SEGFORMER_FINAL_RESULTS_ROOT}/train_kfold\"\n",
    "seg_semi_auto_path = f\"{SEGFORMER_FINAL_RESULTS_ROOT}/train_semi_auto\"\n",
    "save_folder = \"outputs/figures\"\n",
    "\n",
    "seg_model_name = \"segformer\"\n",
    "seg_model_config = \"b2\"\n",
    "seg_variant = \"size_384x96\"\n",
    "seg_results_fname = \"results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8530568847289454, 0.7472556513089399)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting the benchmarks score from kfold training\n",
    "benchmark_dice_score, benchmark_miou_score = 0.0, 0.0\n",
    "kfold_results_path = f'{seg_kfold_path}/{seg_model_name}_{seg_model_config}.{seg_variant}.{seg_results_fname}'\n",
    "\n",
    "with open(f'{kfold_results_path}', 'r') as file:\n",
    "    kfold_data = json.load(file)\n",
    "\n",
    "keys = list(kfold_data.keys())\n",
    "for key in keys:\n",
    "    benchmark_dice_score += kfold_data[key][\"test_dice_score\"]\n",
    "    benchmark_miou_score += kfold_data[key][\"test_miou_score\"]\n",
    "    \n",
    "benchmark_dice_score, benchmark_miou_score = benchmark_dice_score/len(keys), benchmark_miou_score/len(keys)\n",
    "benchmark_dice_score, benchmark_miou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Mask 10% + Generated mask 70% : \t\tPre-SAS Dice: 0.66812\tPost-SAS: 0.71032 \t\tPre-SAS mIoU: 0.50882\tPost-SAS mIoU: 0.55848\n",
      "Real Mask 20% + Generated mask 60% : \t\tPre-SAS Dice: 0.75879\tPost-SAS: 0.80796 \t\tPre-SAS mIoU: 0.61586\tPost-SAS mIoU: 0.68401\n",
      "Real Mask 30% + Generated mask 50% : \t\tPre-SAS Dice: 0.82642\tPost-SAS: 0.84594 \t\tPre-SAS mIoU: 0.70752\tPost-SAS mIoU: 0.73653\n",
      "Real Mask 40% + Generated mask 40% : \t\tPre-SAS Dice: 0.83981\tPost-SAS: 0.83512 \t\tPre-SAS mIoU: 0.72660\tPost-SAS mIoU: 0.72163\n",
      "Real Mask 50% + Generated mask 30% : \t\tPre-SAS Dice: 0.85200\tPost-SAS: 0.86643 \t\tPre-SAS mIoU: 0.74455\tPost-SAS mIoU: 0.76684\n",
      "Real Mask 60% + Generated mask 20% : \t\tPre-SAS Dice: 0.83499\tPost-SAS: 0.86143 \t\tPre-SAS mIoU: 0.71932\tPost-SAS mIoU: 0.75918\n",
      "Real Mask 70% + Generated mask 10% : \t\tPre-SAS Dice: 0.87303\tPost-SAS: 0.86279 \t\tPre-SAS mIoU: 0.77768\tPost-SAS mIoU: 0.76261\n"
     ]
    }
   ],
   "source": [
    "### Generating Train & Test Results\n",
    "with open(f\"{seg_semi_auto_path}/{seg_model_name}_{seg_model_config}.{seg_variant}.{results_fname}\", \"r\") as file:\n",
    "    semi_auto_data = json.load(file)\n",
    "    \n",
    "split_list, split_label_list = [], []\n",
    "presas_dice_score_list, postsas_dice_score_list = [], []\n",
    "presas_miou_score_list, postsas_miou_score_list = [], []\n",
    "    \n",
    "for key in semi_auto_data.keys():\n",
    "    real_data_pct = int(key[15:])\n",
    "    split_list.append(real_data_pct)\n",
    "    split_label_list.append(f'{real_data_pct}%+{80-real_data_pct}%')\n",
    "    presas_dice_score_list.append(semi_auto_data[key][\"presas_test_dice\"])\n",
    "    postsas_dice_score_list.append(semi_auto_data[key][\"postsas_test_dice\"])\n",
    "    presas_miou_score_list.append(semi_auto_data[key][\"presas_test_miou\"])\n",
    "    postsas_miou_score_list.append(semi_auto_data[key][\"postsas_test_miou\"])\n",
    "    print(f'Real Mask {real_data_pct}% + Generated mask {80-real_data_pct}% : \\t\\tPre-SAS Dice: {semi_auto_data[key][\"presas_test_dice\"]:.5f}\\tPost-SAS: {semi_auto_data[key][\"postsas_test_dice\"]:.5f} \\t\\tPre-SAS mIoU: {semi_auto_data[key][\"presas_test_miou\"]:.5f}\\tPost-SAS mIoU: {semi_auto_data[key][\"postsas_test_miou\"]:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_results(benchmark_score=benchmark_dice_score,\n",
    "                  metric_name=\"Dice\",\n",
    "                  split_list=split_list, \n",
    "                  split_label_list=split_label_list,\n",
    "                  split_score_list_pre=presas_dice_score_list, \n",
    "                  split_score_list_post=postsas_dice_score_list, \n",
    "                  savefig_name=f\"{save_folder}/segformer_test_dice_scores.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_results(benchmark_score=benchmark_miou_score,\n",
    "                  metric_name=\"mIoU\",\n",
    "                  split_list=split_list, \n",
    "                  split_label_list=split_label_list,\n",
    "                  split_score_list_pre=presas_miou_score_list, \n",
    "                  split_score_list_post=postsas_miou_score_list, \n",
    "                  savefig_name=f\"{save_folder}/segformer_test_miou_scores.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the SAS mask dice scores\n",
    "gen_dataset_path = f'{seg_semi_auto_path}/gen_data_testset'\n",
    "files = os.listdir(gen_dataset_path)\n",
    "dice_score_files = [fname for fname in files if fname.startswith(\"dice_scores_\")]\n",
    "\n",
    "dice_scores = {\"presas\": {}, \n",
    "               \"postsas\": {}}\n",
    "\n",
    "for file in dice_score_files:\n",
    "    if \"presas\" in file:\n",
    "        category = \"presas\"\n",
    "    elif \"postsas\" in file:\n",
    "        category = \"postsas\"\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    percent = file.split(\"_\")[-1].replace(\".pkl\", \"\")\n",
    "\n",
    "    with open(f\"{gen_dataset_path}/{file}\", \"rb\") as f:\n",
    "        tensor_dice_scores = pickle.load(f)\n",
    "        \n",
    "        dice_scores[category][percent] = [score.item() for idx, score in tensor_dice_scores]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dice_score_vs_data_percent(data=dice_scores, \n",
    "                                model_name=\"SegFormer\", \n",
    "                                model_config=\"B2\", \n",
    "                                save_path=f'{save_folder}/segformer_dice_score_data_percent_comparison.pdf', \n",
    "                                benchmark_dice_score=benchmark_dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-SISM\n",
      "& 1.971& 1.782& 1.523& 1.475& 1.421& 1.506& 1.274\n",
      "post-SISM\n",
      "& 1.904& 1.576& 1.416& 1.475& 1.345& 1.279& 1.349\n"
     ]
    }
   ],
   "source": [
    "all_entropies_segformer = plot_dice_score_entropy(data=dice_scores, model_name=\"UNet\", model_config=\"86\", save_path=f'{save_folder}/unet_dice_score_entropy.pdf')\n",
    "\n",
    "for i in range(len(all_entropies_segformer)):\n",
    "    entropy_str = \"\"\n",
    "    if i==0:\n",
    "        print(\"pre-SISM\")\n",
    "    else:\n",
    "        print(\"post-SISM\")\n",
    "        \n",
    "    for val in all_entropies_segformer[i]:\n",
    "        entropy_str += f\"& {val:.3f}\"\n",
    "        \n",
    "    print(entropy_str)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = multi_model_fit(all_entropies_segformer[1], \"for_segformer_entropies_postsism\", num_data_point=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knull/codespace/semi-automatic-segmentation/utils/visualization.py:520: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  popt, pcov = curve_fit(exp_offset, X_train, y_train,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.31398405, 0.72012987, 1.26451081]),\n",
       " 1.0,\n",
       " array([1.33823269, 1.30039044, 1.28197304, 1.27300949]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_exp_offset(all_entropies_segformer[1], \"for_segformer_entropies_postsism\", num_data_point=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Latex results table: SAS performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-SAS dice: & 0.6681& 0.7588& 0.8264& 0.8398& 0.8520& 0.8350& 0.8730\n",
      "Post-SAS dice: & 0.7103& 0.8080& 0.8459& 0.8351& 0.8664& 0.8614& 0.8628\n",
      "Pre-SAS miou: & 0.5088& 0.6159& 0.7075& 0.7266& 0.7445& 0.7193& 0.7777\n",
      "Post-SAS miou: & 0.5585& 0.6840& 0.7365& 0.7216& 0.7668& 0.7592& 0.7626\n"
     ]
    }
   ],
   "source": [
    "# Dice \n",
    "presas_result_str = \"\"\n",
    "for score in presas_dice_score_list:\n",
    "    presas_result_str += f\"& {score:.4f}\"\n",
    "    \n",
    "postsas_result_str = \"\"\n",
    "for score in postsas_dice_score_list:\n",
    "    postsas_result_str += f\"& {score:.4f}\"\n",
    "    \n",
    "print(f\"Pre-SAS dice: {presas_result_str}\")\n",
    "print(f\"Post-SAS dice: {postsas_result_str}\")\n",
    "\n",
    "# mIoU\n",
    "presas_result_str = \"\"\n",
    "for score in presas_miou_score_list:\n",
    "    presas_result_str += f\"& {score:.4f}\"\n",
    "    \n",
    "postsas_result_str = \"\"\n",
    "for score in postsas_miou_score_list:\n",
    "    postsas_result_str += f\"& {score:.4f}\"\n",
    "    \n",
    "\n",
    "\n",
    "print(f\"Pre-SAS miou: {presas_result_str}\")\n",
    "print(f\"Post-SAS miou: {postsas_result_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Latex results table: Mask Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presas\n",
      "================================================================================\n",
      "Unusables:\t & 4.50& 3.00& 1.00& 1.00& 0.50& 3.00& 1.00\n",
      "Unreliables:\t & 19.50& 13.00& 8.00& 8.00& 6.50& 3.50& 6.50\n",
      "Moderates:\t & 32.00& 22.50& 16.00& 16.00& 15.00& 24.00& 11.50\n",
      "Goods:\t\t & 44.00& 61.50& 75.00& 75.00& 78.00& 69.50& 81.00\n",
      "\n",
      "postsas\n",
      "================================================================================\n",
      "Unusables:\t & 1.00& 1.50& 0.50& 1.50& 1.00& 0.50& 0.50\n",
      "Unreliables:\t & 16.50& 8.50& 7.00& 7.50& 4.50& 6.00& 8.00\n",
      "Moderates:\t & 26.00& 18.50& 14.50& 16.50& 18.00& 11.50& 12.50\n",
      "Goods:\t\t & 56.50& 71.50& 78.00& 74.50& 76.50& 82.00& 79.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = ['presas', 'postsas']\n",
    "percentages = ['10%', '20%', '30%', '40%', '50%', '60%', '70%']\n",
    "\n",
    "unusables, unreliables, moderates, goods = \"\", \"\", \"\", \"\"\n",
    "\n",
    "for category in categories:\n",
    "    unusables_row, unreliables_row, moderates_row, goods_row = \"\", \"\", \"\", \"\"\n",
    "    \n",
    "    for percent in percentages:\n",
    "        scores = sorted(dice_scores[category][percent])\n",
    "        \n",
    "        unusable = sum(1 for score in scores if score == 0.0)\n",
    "        unreliable = sum(1 for score in scores if 0.0 < score <= 0.5)\n",
    "        moderate = sum(1 for score in scores if 0.5 < score <= 0.8)\n",
    "        good = sum(1 for score in scores if score > 0.8)\n",
    "        \n",
    "        unusables_row += f\"& {unusable/len(scores)*100:.2f}\"\n",
    "        unreliables_row += f\"& {unreliable/len(scores)*100:.2f}\"\n",
    "        moderates_row += f\"& {moderate/len(scores)*100:.2f}\"\n",
    "        goods_row += f\"& {good/len(scores)*100:.2f}\"\n",
    "    \n",
    "\n",
    "    print(category)\n",
    "    print(\"=\"*80)\n",
    "    print(\"Unusables:\\t\", unusables_row)\n",
    "    print(\"Unreliables:\\t\", unreliables_row)\n",
    "    print(\"Moderates:\\t\", moderates_row)\n",
    "    print(\"Goods:\\t\\t\", goods_row)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitwise-Modelwise Mask Comparison\n",
    "full_dataset = get_dataset(image_size=(384, 384), mask_size=(96, 96))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = random.choice(full_dataset)\n",
    "results = get_sas_modelwise_results(data=data,\n",
    "                                    model_dir=f\"{seg_semi_auto_path}/models\", \n",
    "                                    model_name=\"segformer\", \n",
    "                                    model_config=\"b2\", \n",
    "                                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.64].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.64].\n"
     ]
    }
   ],
   "source": [
    "plot_modelwise_comparison(image_data=data, results=results, savefig_name=f\"{save_folder}/segformer_modelwise_mask_quality_viz.pdf\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results - UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNET_FINAL_RESULTS_ROOT = f\"{ROOT}/final-results-with-unet\"\n",
    "unet_kfold_path = f\"{UNET_FINAL_RESULTS_ROOT}/train_kfold\"\n",
    "unet_semi_auto_path = f\"{UNET_FINAL_RESULTS_ROOT}/train_semi_auto\"\n",
    "save_folder = \"outputs/figures\"\n",
    "\n",
    "unet_model_name = \"unet\"\n",
    "unet_model_config = \"86\"\n",
    "unet_variant = \"size_384x384\"\n",
    "unet_results_fname = \"results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8607764594695148, 0.7583793801419875)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting the benchmarks score from kfold training\n",
    "benchmark_dice_score, benchmark_miou_score = 0.0, 0.0\n",
    "kfold_results_path = f'{unet_kfold_path}/{unet_model_name}_{unet_model_config}.{unet_variant}.{unet_results_fname}'\n",
    "\n",
    "with open(f'{kfold_results_path}', 'r') as file:\n",
    "    kfold_data = json.load(file)\n",
    "\n",
    "keys = list(kfold_data.keys())\n",
    "for key in keys:\n",
    "    benchmark_dice_score += kfold_data[key][\"test_dice_score\"]\n",
    "    benchmark_miou_score += kfold_data[key][\"test_miou_score\"]\n",
    "    \n",
    "benchmark_dice_score, benchmark_miou_score = benchmark_dice_score/len(keys), benchmark_miou_score/len(keys)\n",
    "benchmark_dice_score, benchmark_miou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Mask 10% + Generated mask 70% : \t\tPre-SAS Dice: 0.72437\tPost-SAS: 0.72660 \t\tPre-SAS mIoU: 0.57329\tPost-SAS mIoU: 0.57562\n",
      "Real Mask 20% + Generated mask 60% : \t\tPre-SAS Dice: 0.78430\tPost-SAS: 0.80296 \t\tPre-SAS mIoU: 0.65131\tPost-SAS mIoU: 0.67580\n",
      "Real Mask 30% + Generated mask 50% : \t\tPre-SAS Dice: 0.81159\tPost-SAS: 0.82418 \t\tPre-SAS mIoU: 0.68744\tPost-SAS mIoU: 0.70501\n",
      "Real Mask 40% + Generated mask 40% : \t\tPre-SAS Dice: 0.82538\tPost-SAS: 0.80888 \t\tPre-SAS mIoU: 0.70606\tPost-SAS mIoU: 0.68377\n",
      "Real Mask 50% + Generated mask 30% : \t\tPre-SAS Dice: 0.83203\tPost-SAS: 0.83420 \t\tPre-SAS mIoU: 0.71563\tPost-SAS mIoU: 0.71868\n",
      "Real Mask 60% + Generated mask 20% : \t\tPre-SAS Dice: 0.84306\tPost-SAS: 0.84378 \t\tPre-SAS mIoU: 0.73157\tPost-SAS mIoU: 0.73244\n",
      "Real Mask 70% + Generated mask 10% : \t\tPre-SAS Dice: 0.85413\tPost-SAS: 0.85353 \t\tPre-SAS mIoU: 0.74849\tPost-SAS mIoU: 0.74697\n"
     ]
    }
   ],
   "source": [
    "### Generating Train & Test Results\n",
    "with open(f\"{unet_semi_auto_path}/{unet_model_name}_{unet_model_config}.{unet_variant}.{unet_results_fname}\", \"r\") as file:\n",
    "    semi_auto_data = json.load(file)\n",
    "    \n",
    "split_list, split_label_list = [], []\n",
    "presas_dice_score_list, postsas_dice_score_list = [], []\n",
    "presas_miou_score_list, postsas_miou_score_list = [], []\n",
    "    \n",
    "for key in semi_auto_data.keys():\n",
    "    real_data_pct = int(key[15:])\n",
    "    split_list.append(real_data_pct)\n",
    "    split_label_list.append(f'{real_data_pct}%+{80-real_data_pct}%')\n",
    "    presas_dice_score_list.append(semi_auto_data[key][\"presas_test_dice\"])\n",
    "    postsas_dice_score_list.append(semi_auto_data[key][\"postsas_test_dice\"])\n",
    "    presas_miou_score_list.append(semi_auto_data[key][\"presas_test_miou\"])\n",
    "    postsas_miou_score_list.append(semi_auto_data[key][\"postsas_test_miou\"])\n",
    "    print(f'Real Mask {real_data_pct}% + Generated mask {80-real_data_pct}% : \\t\\tPre-SAS Dice: {semi_auto_data[key][\"presas_test_dice\"]:.5f}\\tPost-SAS: {semi_auto_data[key][\"postsas_test_dice\"]:.5f} \\t\\tPre-SAS mIoU: {semi_auto_data[key][\"presas_test_miou\"]:.5f}\\tPost-SAS mIoU: {semi_auto_data[key][\"postsas_test_miou\"]:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_results(benchmark_score=benchmark_dice_score,\n",
    "                  metric_name=\"Dice\",\n",
    "                  split_list=split_list, \n",
    "                  split_label_list=split_label_list,\n",
    "                  split_score_list_pre=presas_dice_score_list, \n",
    "                  split_score_list_post=postsas_dice_score_list, \n",
    "                  savefig_name=f\"{save_folder}/unet_test_dice_scores.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_results(benchmark_score=benchmark_miou_score,\n",
    "                  metric_name=\"mIoU\",\n",
    "                  split_list=split_list, \n",
    "                  split_label_list=split_label_list,\n",
    "                  split_score_list_pre=presas_miou_score_list, \n",
    "                  split_score_list_post=postsas_miou_score_list, \n",
    "                  savefig_name=f\"{save_folder}/unet_test_miou_scores.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the SAS mask dice scores\n",
    "gen_dataset_path = f'{unet_semi_auto_path}/gen_data_testset'\n",
    "files = os.listdir(gen_dataset_path)\n",
    "dice_score_files = [fname for fname in files if fname.startswith(\"dice_scores_\")]\n",
    "\n",
    "dice_scores = {\"presas\": {}, \n",
    "               \"postsas\": {}}\n",
    "\n",
    "for file in dice_score_files:\n",
    "    if \"presas\" in file:\n",
    "        category = \"presas\"\n",
    "    elif \"postsas\" in file:\n",
    "        category = \"postsas\"\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    percent = file.split(\"_\")[-1].replace(\".pkl\", \"\")\n",
    "\n",
    "    with open(f\"{gen_dataset_path}/{file}\", \"rb\") as f:\n",
    "        tensor_dice_scores = pickle.load(f)\n",
    "        \n",
    "        dice_scores[category][percent] = [score.item() for idx, score in tensor_dice_scores]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dice_score_vs_data_percent(data=dice_scores, \n",
    "                                model_name=\"UNet\", \n",
    "                                model_config=\"86\", \n",
    "                                save_path=f'{save_folder}/unet_dice_score_data_percent_comparison.pdf', \n",
    "                                benchmark_dice_score=benchmark_dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-SISM\n",
      "& 1.854& 1.750& 1.593& 1.531& 1.473& 1.473& 1.404\n",
      "post-SISM\n",
      "& 1.879& 1.663& 1.558& 1.574& 1.476& 1.494& 1.430\n"
     ]
    }
   ],
   "source": [
    "all_entropies_unet = plot_dice_score_entropy(data=dice_scores, model_name=\"UNet\", model_config=\"86\", save_path=f'{save_folder}/unet_dice_score_entropy.pdf')\n",
    "\n",
    "for i in range(len(all_entropies_unet)):\n",
    "    entropy_str = \"\"\n",
    "\n",
    "    if i==0:\n",
    "        print(\"pre-SISM\")\n",
    "    else:\n",
    "        print(\"post-SISM\")\n",
    "        \n",
    "    for val in all_entropies_unet[i]:\n",
    "        entropy_str += f\"& {val:.3f}\"\n",
    "        \n",
    "    print(entropy_str)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = multi_model_fit(all_entropies_unet[1], \"for_unet_entropies_postsism\", num_data_point=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knull/codespace/semi-automatic-segmentation/utils/visualization.py:581: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  popt, _ = curve_fit(exp_offset, X_train, y_train,\n",
      "/home/knull/codespace/semi-automatic-segmentation/utils/visualization.py:581: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  popt, _ = curve_fit(exp_offset, X_train, y_train,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.31398405, 0.72012987, 1.26451081]),\n",
       " 1.0,\n",
       " array([1.33823269, 1.30039044, 1.28197304, 1.27300949]),\n",
       " array([0.86282984, 0.71712771, 1.4574832 ]),\n",
       " 1.0,\n",
       " array([1.50647764, 1.48139995, 1.46915822, 1.46318239]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_exp_offset_dual(entropy_values1=all_entropies_segformer[1], \n",
    "                    entropy_values2=all_entropies_unet[1], \n",
    "                    save_fname=\"optimized_training_set_estimation_with_asymptotic_exp_decay\", \n",
    "                    num_data_point=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_exp_offset(all_entropies_unet[1], \"for_unet_entropies_postsism\", num_data_point=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Latex results table: SAS performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-SAS dice: & 0.7244& 0.7843& 0.8116& 0.8254& 0.8320& 0.8431& 0.8541\n",
      "Post-SAS dice: & 0.7266& 0.8030& 0.8242& 0.8089& 0.8342& 0.8438& 0.8535\n",
      "Pre-SAS miou: & 0.5733& 0.6513& 0.6874& 0.7061& 0.7156& 0.7316& 0.7485\n",
      "Post-SAS miou: & 0.5756& 0.6758& 0.7050& 0.6838& 0.7187& 0.7324& 0.7470\n"
     ]
    }
   ],
   "source": [
    "# Dice \n",
    "presas_result_str = \"\"\n",
    "for score in presas_dice_score_list:\n",
    "    presas_result_str += f\"& {score:.4f}\"\n",
    "    \n",
    "postsas_result_str = \"\"\n",
    "for score in postsas_dice_score_list:\n",
    "    postsas_result_str += f\"& {score:.4f}\"\n",
    "    \n",
    "print(f\"Pre-SAS dice: {presas_result_str}\")\n",
    "print(f\"Post-SAS dice: {postsas_result_str}\")\n",
    "\n",
    "# mIoU\n",
    "presas_result_str = \"\"\n",
    "for score in presas_miou_score_list:\n",
    "    presas_result_str += f\"& {score:.4f}\"\n",
    "    \n",
    "postsas_result_str = \"\"\n",
    "for score in postsas_miou_score_list:\n",
    "    postsas_result_str += f\"& {score:.4f}\"\n",
    "    \n",
    "\n",
    "\n",
    "print(f\"Pre-SAS miou: {presas_result_str}\")\n",
    "print(f\"Post-SAS miou: {postsas_result_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Latex results table: Mask Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presas\n",
      "================================================================================\n",
      "Unusables:\t & 1.00& 0.00& 0.50& 0.50& 0.00& 0.00& 0.00\n",
      "Unreliables:\t & 13.50& 13.50& 9.50& 8.50& 8.00& 7.50& 6.50\n",
      "Moderates:\t & 28.50& 24.50& 20.00& 22.00& 22.50& 23.00& 19.50\n",
      "Goods:\t\t & 57.00& 62.00& 70.00& 69.00& 69.50& 69.50& 74.00\n",
      "\n",
      "postsas\n",
      "================================================================================\n",
      "Unusables:\t & 0.50& 0.50& 0.50& 0.50& 0.50& 0.00& 0.50\n",
      "Unreliables:\t & 18.00& 10.50& 7.00& 10.00& 7.50& 7.50& 7.00\n",
      "Moderates:\t & 24.00& 28.50& 21.00& 19.00& 21.00& 23.00& 19.00\n",
      "Goods:\t\t & 57.50& 60.50& 71.50& 70.50& 71.00& 69.50& 73.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = ['presas', 'postsas']\n",
    "percentages = ['10%', '20%', '30%', '40%', '50%', '60%', '70%']\n",
    "\n",
    "unusables, unreliables, moderates, goods = \"\", \"\", \"\", \"\"\n",
    "\n",
    "for category in categories:\n",
    "    unusables_row, unreliables_row, moderates_row, goods_row = \"\", \"\", \"\", \"\"\n",
    "    \n",
    "    for percent in percentages:\n",
    "        scores = sorted(dice_scores[category][percent])\n",
    "        \n",
    "        unusable = sum(1 for score in scores if score == 0.0)\n",
    "        unreliable = sum(1 for score in scores if 0.0 < score <= 0.5)\n",
    "        moderate = sum(1 for score in scores if 0.5 < score <= 0.8)\n",
    "        good = sum(1 for score in scores if score > 0.8)\n",
    "        \n",
    "        unusables_row += f\"& {unusable/len(scores)*100:.2f}\"\n",
    "        unreliables_row += f\"& {unreliable/len(scores)*100:.2f}\"\n",
    "        moderates_row += f\"& {moderate/len(scores)*100:.2f}\"\n",
    "        goods_row += f\"& {good/len(scores)*100:.2f}\"\n",
    "    \n",
    "\n",
    "    print(category)\n",
    "    print(\"=\"*80)\n",
    "    print(\"Unusables:\\t\", unusables_row)\n",
    "    print(\"Unreliables:\\t\", unreliables_row)\n",
    "    print(\"Moderates:\\t\", moderates_row)\n",
    "    print(\"Goods:\\t\\t\", goods_row)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Splitwise-Modelwise Mask Comparison\n",
    "# full_dataset = get_dataset(image_size=(256, 256), mask_size=(256, 256))\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# data = random.choice(full_dataset)\n",
    "\n",
    "# results = get_sas_modelwise_results(data=data,\n",
    "#                                     model_dir=f\"{unet_semi_auto_path}/models\", \n",
    "#                                     model_name=\"unet\", \n",
    "#                                     model_config=\"114\", \n",
    "#                                     device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_modelwise_comparison(image_data=data, results=results, savefig_name=f\"{save_folder}/unet_modelwise_mask_quality_viz.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
